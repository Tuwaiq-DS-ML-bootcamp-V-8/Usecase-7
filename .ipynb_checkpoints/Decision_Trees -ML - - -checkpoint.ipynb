{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"final_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d = dtale.show(df)\n",
    "#d.open_browser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Simple EDA + Data Quality checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uniqeness\n",
    "df.drop_duplicates(inplace=True)\n",
    "df[df.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accurecy - Outlier\n",
    "# drop unneccsery columns \n",
    "df.drop(columns=['player'], inplace=True)\n",
    "df.drop(columns=['name'], inplace=True)\n",
    "df.drop(columns=['winger'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows \n",
    "df.drop(df[(df['age'] <= 18) | (df['age'] >= 40)].index, inplace=True)\n",
    "df.drop(df[(df['current_value'] == 0) | (df['highest_value'] == 0)].index, inplace=True)\n",
    "df.drop(df[(df['appearance'] == 0) | (df['appearance'] == 95)].index, inplace=True)\n",
    "df.drop(df[df['current_value'] >= 7000000].index, inplace=True)\n",
    "df.drop(df[df['current_value'] < 10000].index, inplace=True)\n",
    "df.drop(df[df['highest_value'] >= 8500000].index, inplace=True)\n",
    "df.drop(df[df['highest_value'] < 250000].index, inplace=True)\n",
    "df.drop(df[df['height'] > 195].index, inplace=True)\n",
    "df.drop(df[df['height'] <= 160].index, inplace=True)\n",
    "#df.drop(df[(df['age'] == 26) & (df['award'] == 0)].index, inplace=True)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Completeness\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accurecy types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accurecy - Outlier\n",
    "\n",
    "# Convert categorical variables using OneHotEncoding\n",
    "categorical_features = ['team', 'position']\n",
    "numeric_features = ['age', 'appearance', 'goals', 'assists',\n",
    "       'yellow cards', 'second yellow cards', 'red cards', 'goals conceded',\n",
    "       'clean sheets', 'minutes played', 'days_injured', 'games_injured',\n",
    "       'award', 'current_value', 'highest_value', 'position_encoded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[(df['age'] <= 18) | (df['age'] >= 40)].index, inplace=True)\n",
    "df.drop(df[(df['current_value'] == 0) | (df['highest_value'] == 0)].index, inplace=True)\n",
    "df.drop(df[(df['appearance'] == 0) | (df['appearance'] == 95)].index, inplace=True)\n",
    "df.drop(df[df['current_value'] >= 7000000].index, inplace=True)\n",
    "df.drop(df[df['current_value'] < 10000].index, inplace=True)\n",
    "df.drop(df[df['highest_value'] >= 8500000].index, inplace=True)\n",
    "df.drop(df[df['highest_value'] < 250000].index, inplace=True)\n",
    "df.drop(df[df['height'] > 195].index, inplace=True)\n",
    "df.drop(df[df['height'] <= 160].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in categorical_features:\n",
    "    print (df[i].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the frequency of each 'Type'\n",
    "type_counts = df['position'].value_counts()\n",
    "type_counts\n",
    "# Filter 'Type' values that appear 10 or more times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[df['Type']=='Other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the occurrences of each position\n",
    "position_counts = df['position'].value_counts()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "position_counts.plot(kind='bar', color='coral')\n",
    "plt.xlabel('position')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Count of Each Position')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(axis='y')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the occurrences of each position\n",
    "position_counts = df['position_encoded'].value_counts()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "position_counts.plot(kind='bar', color='coral')\n",
    "plt.xlabel('position_encoded')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Count of Each Position')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(axis='y')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "plt.hist(df['age'], bins=100, color='skyblue', edgecolor='black')\n",
    "plt.xlabel('age')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Age')\n",
    "plt.grid(axis='y')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Feature scaling\n",
    "2. Aggregation\n",
    "3. One hot coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p35, p75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot coding\n",
    "df = pd.get_dummies(df, columns=categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the 35th and 75th percentiles of the price\n",
    "p35 = df['goals'].quantile(0.35)\n",
    "p75 = df['goals'].quantile(0.75)\n",
    "\n",
    "# Function to categorize prices\n",
    "def categorize_price(price):\n",
    "    if price < p35:\n",
    "        return 'less goals'\n",
    "    elif price < p75:\n",
    "        return 'moderate goals'\n",
    "    else:\n",
    "        return 'low goals'\n",
    "\n",
    "\n",
    "# Verify the distribution of the new categories\n",
    "print(df['goals'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "df['goals'] = encoder.fit_transform(df['goals'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['car_price_category'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder = LabelEncoder()\n",
    "#df['car_price_category_encoded'] = encoder.fit_transform(df['car_price_category'])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.corr(), annot=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = df.corr(numeric_only=True)\n",
    "#print(correlation['Price'].sort_values(ascending=False))\n",
    "print(correlation['position_encoded'].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the correlation threshold\n",
    "threshold = 0.2  # You can change this value based on your requirement\n",
    "\n",
    "# Filter the correlations\n",
    "# We use `abs()` for absolute value to consider both strong positive and negative correlations\n",
    "selected_features = correlation[abs(correlation['position_encoded']) > \\\n",
    "threshold]['position_encoded'].index\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['height', 'goals', 'assists', 'goals conceded', 'position_encoded',\n",
    "       'position_Attack Centre-Forward', 'position_Attack-LeftWinger',\n",
    "       'position_Attack-RightWinger', 'position_Defender Centre-Back',\n",
    "       'position_Defender Left-Back', 'position_Defender Right-Back',\n",
    "       'position_Goalkeeper']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[selected_features]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Prepare train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "X = df.drop(['position_encoded'], axis=1)\n",
    "y = df['position_encoded']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    shuffle=True,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buliding the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_classifier = DecisionTreeClassifier()\n",
    "rf_classifier = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'max_depth': [4, 5, 6, 7, 8],   # adjust tree depth\n",
    "    'n_estimators':[35, 40, 50, 60]      # adjust num trees to build before taking the maximum voting or averages of predictions\n",
    "}\n",
    "grid_search = GridSearchCV(estimator=rf_classifier,\n",
    "                           param_grid=param_grid,\n",
    "                           cv=5,\n",
    "                           scoring='f1_macro', \n",
    "                           verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model on the training data\n",
    "dt_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict and evaluate the model\n",
    "y_pred_dt = dt_classifier.predict(X_test)\n",
    "y_pred_rf = rf_classifier.predict(X_test)\n",
    "y_pred_rf_g = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each row of the model.coef_ matrix tells you how each feature affects being in the corresponding class versus any other class\n",
    "coeff_df = pd.DataFrame(model.coef_[2],X.columns,columns=['Coefficient'])\n",
    "coeff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.intercept_) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our benchmark model\n",
    "base_model = round(df['position_encoded'].value_counts()[1]/df.shape[0]*100, 2)\n",
    "base_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = model.predict(X_train_scaled)\n",
    "accuracy = accuracy_score(y_train, y_pred_train)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred,\n",
    "                                        display_labels=model.classes_,\n",
    "                                        cmap=\"Greens\",\n",
    "                                        xticks_rotation='vertical')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Precision\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "print(f\"Precision: {precision:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Recall\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "print(f\"Recall: {recall:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate F1 Score\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print(f\"F1 Score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
